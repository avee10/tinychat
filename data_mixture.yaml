seq_len: 2048
tokenizer: ./tokenizer.model         # or "openai/tiktoken:gpt2" etc.

#mixture:
#  - name: aveekmukherjee/wikivoyage-eu-india-sections
#    split: train
#    weight: 0.25
#    text_key: text
#    preproc: section_header          # prepend "== {section} =="
#
#  - name: aveekmukherjee/wikipedia-travel-eu-india
#    split: train
#    weight: 0.10
#    text_key: text
#    preproc: section_header
#
#  - name: you/fineweb-edu-mini       # your curated base slice
#    split: train
#    weight: 0.55
#    text_key: text
#
#  - name: aveekmukherjee/travel-mid-no-tools-eu-india
#    split: train
#    files: ["compress.jsonl","qa.jsonl"]   # mid buckets
#    weight: 0.10
#    text_key: auto                        # derive from task (see code)

mixture:
  - {name: "aveekmukherjee/wikivoyage-eu-india-sections", weight: 0.25, text_key: text, preproc: section_header}
  - {name: "aveekmukherjee/wikipedia-travel-eu-india",    weight: 0.15, text_key: text, preproc: section_header}
  - {name: "aveekmukherjee/travel-mid-no-tools-eu-india", weight: 0.10, text_key: auto}
  - {name: "fineweb-edu-mini",                            weight: 0.50, text_key: text}
